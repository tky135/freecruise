seed: 0
dataset: waymo/3cams

# ------------- Trainer ------------ #
trainer:
  type: models.trainers.SingleTrainer
  optim:
    num_iters: 30000
    use_grad_scaler: false
    cache_buffer_freq: -1 # if > 0, use error based image sampler for training
  render:
    near_plane: 0.1 # near plane for rendering
    far_plane: 10000000000.0 # far plane for rendering
    antialiased: false # whether to use antialiasing for gaussian rendering, supported by gsplat kernel
    packed: false # whether to use packed rendering, supported by gsplat kernel
    absgrad: false # whether to use absolute gradient for rendering, supported by gsplat kernel
    sparse_grad: false # whether to use sparse gradient for rendering, supported by gsplat kernel
    batch_size: 1 # batch size for rendering, currently only support 1
  losses:
    rgb:
      w: 0.8
    ssim:
      w: 0.2
    mask:
      w: 1.0
      opacity_loss_type: safe_bce # choose from [bce, safe_bce]
    depth:
      w: 0.1 # weight of depth loss
      inverse_depth: True # whether to use inverse depth, NOTE that when set to True, must normalize=True
      normalize: False # whether to normalize depth loss
      loss_type: l1 # choose from ["l1", "l2"]
      reduction: mean_on_hw # choose from ["mean_on_hit", "mean_on_hw", "sum", "none"]
      # refer to pvg codebase
      weight_decay: 1.0
    opacity_entropy:
      w: 0.05
    inverse_depth_smoothness:
      w: 0.001
  res_schedule:
    double_steps: 5000 # training starts at 1/d resolution, every n steps this is doubled
    downscale_times: 3 # at the beginning, resolution is 1/2^d, where d is this number
  gaussian_optim_general_cfg:
    xyz:
      lr: 1.6e-04
      lr_final: 1.6e-06
      scale_factor: scene_radius # str or float, if "scene_scale", scale the learning rate by the scene scale
    sh_dc:
      lr: 0.0025
    sh_rest:
      lr: 0.000125
    opacity:
      lr: 0.005
    scaling:
      lr: 0.005
    rotation:
      lr: 0.001
  gaussian_ctrl_general_cfg:
    warmup_steps: 500             # warmup steps for alpha
    reset_alpha_interval: 3000    # reset alpha every n steps
    refine_interval: 100          # refine gaussians every n steps
    sh_degree_interval: 2000      # every n intervals turn on another sh degree
    n_split_samples: 2            # number of samples to split gaussians into
    # may differ in different models
    reset_alpha_value: 0.01       # reset alpha to this value
    densify_grad_thresh: 0.0002   # above this grad, gaussians are densified
    densify_size_thresh: 0.01   # below this size, gaussians are *duplicated*, otherwise split
    cull_alpha_thresh: 0.005       # threshold of opacity for culling gaussians
    cull_scale_thresh: 0.5        # threshold of scale for culling gaussians
    cull_screen_size: 0.15        # if a gaussian is more than this percent of screen space, cull it
    split_screen_size: 0.05       # if a gaussian is more than this percent of screen space, split it
    stop_screen_size_at: 4000     # stop culling/splitting at this step WRT screen size of gaussians
    stop_split_at: 20000          # stop splitting at this step
    sh_degree: 3                  # sh degree for gaussians

# ------------- Model ------------ #
model:
  Background:
    type: models.gaussians.PeriodicVibrationGaussians
    init:
      from_lidar:
        num_samples: 800_000
        return_color: True
        return_normalized_time: True
      near_randoms: 100_000
      far_randoms: 100_000
    reg:
      sharp_shape_reg:
        w: 1.
        step_interval: 10
        max_gauss_ratio: 10.       # threshold of ratio of gaussian max to min scale before applying regularization loss from the PhysGaussian paper
      velocity_reg:
        w: 0.001
    optim:
      velocity:
        lr: 1.0e-3
        scale_factor: scene_radius
      life_span:
        lr: 2.0e-3
      life_peak:
        lr: 8.0e-4
        lr_final: 8.0e-6
    ctrl:
      # pvg specific
      cycle_length: 0.2
      time_interval: 0.02
      enable_temporal_smoothing: True
      smooth_probability: 0.5
      distribution_span: 1.5 # unit: frame interval
      betas_init: 0.1
      densify_until_num_points: 3_000_000
      densify_t_grad_thresh: 0.002
      densify_t_size_thresh: 0.01
      no_time_split: true
  Sky:
    type: models.modules.EnvLight
    params:
      resolution: 1024
    optim:
      all:
        lr: 0.01
  Affine:
    type: models.modules.AffineTransform
    params:
      embedding_dim: 4
      base_mlp_layer_width: 64
      pixel_affine: False
    optim:
      all:
        lr: 1.0e-5
        weight_decay: 1.0e-6
  CamPose:
    type: models.modules.CameraOptModule
    optim:
      all:
        lr: 1.0e-5
        weight_decay: 1.0e-6

# ------------- render ------------ #
render:
  fps: 10 # frames per second for the main rendered output
  render_full: True # whether to render full resolution videos
  render_test: True # whether to render test set
  render_novel: 
    traj_types:
      - front_center_interp # type of trajectory for novel view synthesis
    fps: 24 # frames per second for novel view rendering
  vis_lidar: False # whether to visualize lidar points on ground truth images
  vis_sky: False # whether to include "rgb_sky" and "rgb_sky_blend" in rendered keys
  vis_error: False # whether to include "rgb_error_map" in rendered keys

# ------------- logging ------------ #
logging:
  vis_freq: 2000 # how often to visualize training stats
  print_freq: 500 # how often to print training stats
  saveckpt_freq: 15000 # how often to save checkpoints
  save_seperate_video: True # whether to save seperate videos for each scene